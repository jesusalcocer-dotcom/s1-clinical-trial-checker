{
  "version": "5.0",
  "description": "Operationalized check definitions for the S-1 Clinical Trial Disclosure Checker. Each check includes pseudocode logic, grep patterns, thresholds, LLM prompt templates with slots, and references to precedent language in other reference files.",
  "checks": [
    {
      "id": "basic_disclosure",
      "display_name": "Basic Disclosure",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Verify the S-1 provides fundamental clinical trial information: drug identity, indication, modality, development stage, and no-approved-products statement.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "indication_check",
          "executor": "code",
          "action": "grep for disease/condition name within 500 chars of candidate name",
          "patterns": ["for the treatment of", "in patients with", "for [A-Z]"],
          "output": "PRESENT (with text) | ABSENT"
        },
        {
          "step": 2,
          "name": "modality_check",
          "executor": "code",
          "action": "grep for modality keywords within candidate passages",
          "patterns": ["small molecule", "antibody", "monoclonal", "gene therapy", "cell therapy", "peptide", "oligonucleotide", "vaccine", "bispecific", "ADC", "conjugate"],
          "inn_suffixes": ["-mab", "-nib", "-tide", "-gene", "-mer", "-tinib", "-ciclib"],
          "output": "PRESENT (with text) | ABSENT"
        },
        {
          "step": 3,
          "name": "development_stage_check",
          "executor": "code",
          "action": "extract all phase mentions and check coherent progression",
          "patterns": ["Phase [1-3]", "preclinical", "IND", "NDA", "BLA"],
          "output": "CLEAR | UNCLEAR | DATES_MISSING"
        },
        {
          "step": 4,
          "name": "no_approved_products_check",
          "executor": "code",
          "action": "grep for standard clinical-stage disclosures",
          "patterns": ["no approved products", "clinical-stage", "not generated.*revenue", "no products.*approved"],
          "output": "PRESENT (with text) | ABSENT"
        }
      ],
      "escalation": "none",
      "thresholds": {
        "green": "all elements PRESENT",
        "yellow": "any element ABSENT",
        "red": "N/A — this is a presence check"
      },
      "legal_basis_ids": ["rule_408", "section_11"],
      "comment_letter_excerpt_ids": ["excerpt_trial_design_001"]
    },
    {
      "id": "phase_labels",
      "display_name": "Phase Labels",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Check whether combined phase labels (e.g., Phase 1/2) are adequately explained with distinct portions described.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "combined_label_scan",
          "executor": "code",
          "action": "regex for combined phase labels",
          "patterns": ["Phase\\s*[12]\\s*/\\s*[23]", "Phase\\s+\\d[ab]?\\s*/\\s*\\d[ab]?"],
          "output": "list of combined labels with positions",
          "short_circuit": "IF no combined labels -> GREEN, done"
        },
        {
          "step": 2,
          "name": "explanation_search",
          "executor": "code",
          "action": "for each combined label, extract 1000 chars context and search for explanation terms",
          "patterns": ["Phase 1 portion", "dose escalation", "MTD", "RP2D", "Phase 2 portion", "expansion", "efficacy", "activity", "transition", "criteria", "trigger"],
          "output": "explanation_found: true | false per label"
        },
        {
          "step": 3,
          "name": "llm_assessment",
          "executor": "llm",
          "trigger": "step 2 output has any explanation_found == false",
          "prompt_template": "The S-1 uses the label '{{COMBINED_LABEL}}' in this context:\n'{{S1_PASSAGE}}'\n\nThe SEC has required companies to explain what each phase portion involves. Here is the SEC's comment in a comparable situation:\n'{{PRECEDENT_COMMENT}}'\n\nDoes this S-1 passage adequately explain both portions?",
          "slot_sources": {
            "COMBINED_LABEL": "step 1 output",
            "S1_PASSAGE": "step 2 context extraction",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_phase_001.sec_comment_verbatim"
          }
        }
      ],
      "thresholds": {
        "green": "no combined labels, or all combined labels explained",
        "yellow": "combined labels present without adequate explanation"
      },
      "legal_basis_ids": ["rule_408"],
      "comment_letter_excerpt_ids": ["excerpt_phase_001", "excerpt_phase_002", "excerpt_phase_003"],
      "comparison_pairs": [
        {
          "id": "sensei_phase_labels",
          "company": "Sensei Biotherapeutics",
          "filing_type": "S-1",
          "filing_date": "2021-01-15",
          "s1_text_challenged": "Phase 1/2 and Phase 2/3 — throughout the prospectus",
          "sec_comment_verbatim": "Please remove all references to 'Phase 1/2' and 'Phase 2/3' clinical trials throughout the prospectus and instead reference either phase 1, 2, or 3 distinctly or tell us the basis for your belief that have been approved to conduct a Phase 1/2 trial.",
          "what_sec_required": "Remove combined phase labels or provide basis for belief that combined-phase trials were approved by FDA",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "The canonical SEC comment on Phase 1/2 nomenclature. Shows the SEC's concern that combined labels imply shorter development."
        },
        {
          "id": "nuvalent_phase_labels",
          "company": "Nuvalent, Inc.",
          "filing_type": "S-1",
          "filing_date": "2021-07-14",
          "s1_text_challenged": "Phase 1/2 — throughout the prospectus",
          "sec_comment_verbatim": "Please remove all references to 'Phase 1/2' clinical trials throughout the prospectus and instead reference either phase 1, 2, or 3 distinctly or tell us the basis for your belief that have been approved to conduct a Phase 1/2 trial.",
          "what_sec_required": "Remove combined phase labels or justify with FDA basis",
          "severity_level": "MEDIUM",
          "useful_for_comparison_because": "Shows another successful defense of Phase 1/2 label. Key elements: FDA pre-IND meeting, IND accepted under that title, distinct portions described."
        },
        {
          "id": "taysha_phase_labels",
          "company": "Taysha Gene Therapies, Inc.",
          "filing_type": "S-1",
          "filing_date": "2020-09-24",
          "s1_text_challenged": "Pipeline table showing combined Phase 1/2 for all product candidates",
          "sec_comment_verbatim": "Include separate columns for Phase 1 and Phase 2 trials or tell us the basis for your belief that you will be able to conduct Phase 1/2 trials for all your product candidates.",
          "what_sec_required": "Separate Phase 1 and Phase 2 into distinct columns in pipeline table, or justify combined Phase 1/2 for all products",
          "severity_level": "MEDIUM",
          "useful_for_comparison_because": "Demonstrates a regulatory/scientific justification for combined Phase 1/2 in gene therapy."
        }
      ],
      "severity_spectrum": {
        "description": "Phase label severity depends on whether the combined label is explained and whether FDA has accepted the protocol design",
        "levels": [
          {"label": "GREEN_CLEAR", "description": "No combined labels, OR combined label with explanation of distinct portions and FDA basis cited", "example": "Phase 1/2 study with dose escalation (Phase 1) and expansion cohort (Phase 2) per FDA-accepted protocol"},
          {"label": "YELLOW_BORDERLINE", "description": "Combined label present with some explanation but missing FDA basis", "example": "Phase 1/2 with description of dose escalation but no mention of FDA accepting the design"},
          {"label": "RED_MATCHES_CHALLENGED", "description": "Combined label used throughout without any explanation of distinct portions", "example": "Repeated use of 'Phase 1/2' and 'Phase 2/3' with no discussion of what each portion involves"}
        ]
      },
      "escalation_prompt": {
        "trigger": "combined_label_without_explanation",
        "source_doc": "reference/check2_phase_labels.md",
        "source_section": "ESCALATION_PROMPT_ARCHITECTURE",
        "steps": [
          {
            "step": 1,
            "name": "text_to_text_comparison",
            "executor": "llm",
            "prompt_source": "reference/check2_phase_labels.md#STEP_1",
            "slots": ["{{S1_TEXT}}", "{{COMPARISON_PAIRS}}"],
            "output_format": {"type": "json", "keys": ["classification", "explanation_present", "severity", "step1_assessment"]}
          },
          {
            "step": 2,
            "name": "web_search_augmentation",
            "executor": "web_search",
            "trigger": "fires_only_on_CONCERN_or_SIGNIFICANT_CONCERN",
            "query_template": "SEC comment letter Phase 1/2 nomenclature biotech {{YEAR_RANGE}}",
            "output_keys": ["search_result", "assessment: STRENGTHEN|WEAKEN|NEUTRAL"]
          },
          {
            "step": 3,
            "name": "final_determination",
            "executor": "llm",
            "prompt_source": "reference/check2_phase_labels.md#STEP_3",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative"]
          }
        ]
      }
    },
    {
      "id": "preclinical_framing",
      "display_name": "Preclinical Framing",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Ensure preclinical/animal data is appropriately framed without implying established clinical safety or efficacy. Check MoA language uses hypothetical framing.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "preclinical_reference_scan",
          "executor": "code",
          "action": "identify preclinical references",
          "patterns": ["preclinical", "animal", "mouse", "rat", "primate", "in vitro", "in vivo", "xenograft", "DIO model", "knockout"],
          "short_circuit": "IF none found -> N/A, skip"
        },
        {
          "step": 2,
          "name": "caveat_check",
          "executor": "code",
          "action": "for each preclinical reference, check for translation risk caveat within 2000 chars",
          "patterns": ["may not be predictive", "no assurance", "animal.*not.*predict", "preclinical.*may not.*translate"],
          "output": "CAVEAT_PRESENT | CAVEAT_ABSENT per reference"
        },
        {
          "step": 3,
          "name": "moa_classification",
          "executor": "code",
          "action": "classify MoA language as HYPOTHETICAL or FACTUAL",
          "hypothetical_markers": ["designed to", "intended to", "aims to", "believed to", "may", "potentially"],
          "factual_markers": ["has shown", "demonstrates", "induces", "activates", "inhibits"],
          "output": "classification per MoA sentence",
          "short_circuit": "IF all hypothetical -> GREEN"
        },
        {
          "step": 4,
          "name": "llm_moa_assessment",
          "executor": "llm",
          "trigger": "step 3 has any FACTUAL classification",
          "prompt_template": "This S-1 states: '{{MOA_STATEMENT}}'\nThis describes the drug's mechanism using factual language ('{{SPECIFIC_VERB}}') rather than hypothetical framing.\n\nThe SEC has challenged similar language. In {{COMPANY}}'s S-1, the SEC commented:\n'{{PRECEDENT_COMMENT}}'\n\nIs this S-1's MoA statement:\n(a) Supported by clinical (human) data cited elsewhere in the S-1?\n(b) Based only on preclinical data but stated as established fact?\n(c) Appropriately qualified despite the factual verb?",
          "slot_sources": {
            "MOA_STATEMENT": "step 3 factual sentences",
            "SPECIFIC_VERB": "step 3 matched factual marker",
            "COMPANY": "comment_letter_excerpts.json -> excerpt_preclinical_001.company",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_preclinical_001.sec_comment_verbatim"
          }
        }
      ],
      "thresholds": {
        "green": "all MoA language hypothetical, caveats present",
        "yellow": "factual MoA language found but context may justify",
        "red": "factual MoA language with no clinical data support and no caveat"
      },
      "legal_basis_ids": ["rule_408", "section_11"],
      "comment_letter_excerpt_ids": ["excerpt_preclinical_001", "excerpt_preclinical_002", "excerpt_preclinical_003"],
      "comparison_pairs": [
        {
          "id": "curanex_preclinical",
          "company": "Curanex Pharmaceuticals",
          "filing_type": "S-1/A",
          "filing_date": "2024-07-17",
          "s1_text_challenged": "[PLACEHOLDER — to be filled from SEC filing]",
          "sec_comment_verbatim": "You state that your lead product candidate, Phyto-N, has demonstrated promising efficacy in animal models and has a long history of safe use in traditional medicine. Safety and efficacy determinations are solely within the authority of the FDA or comparable foreign regulator.",
          "what_sec_required": "Remove all safety/efficacy inferences from preclinical data. Objective data and endpoint results are acceptable without efficacy conclusions.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Comprehensive example of preclinical claims being struck. Covers both animal model efficacy claims and traditional use safety claims.",
          "_todo": "Fetch S-1 text from SEC EDGAR for Curanex CIK 0002025942"
        },
        {
          "id": "virpax_preclinical",
          "company": "Virpax Pharmaceuticals, Inc.",
          "filing_type": "S-1",
          "filing_date": "2020-09-04",
          "s1_text_challenged": "[PLACEHOLDER — to be filled from SEC filing]",
          "sec_comment_verbatim": "We note your disclosure that early animal studies indicate that Probudur may provide pain control for up to 96 hours. Please revise these and similar statements throughout your registration statement that state or imply that your product candidates are safe or effective.",
          "what_sec_required": "Remove statements implying safety or efficacy from animal data. Add detailed preclinical methodology disclosure.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Shows SEC requiring not just removal of claims but affirmative addition of methodology details.",
          "_todo": "Fetch S-1 text from SEC EDGAR for Virpax CIK 0001708331"
        }
      ],
      "severity_spectrum": {
        "description": "Preclinical framing severity depends on how strongly efficacy/safety is asserted from non-clinical data",
        "levels": [
          {"label": "GREEN_CLEAR", "description": "Preclinical data presented with hypothetical framing and translation-risk caveats", "example": "'In preclinical models, the drug candidate was designed to inhibit X. Animal results may not be predictive of human outcomes.'"},
          {"label": "YELLOW_BORDERLINE", "description": "Factual language for MoA but with nearby caveats", "example": "'The drug inhibits X in animal models' with nearby caveat about predictiveness"},
          {"label": "RED_MATCHES_CHALLENGED", "description": "Safety or efficacy conclusions drawn from preclinical data", "example": "'Demonstrated promising efficacy in animal models' or 'long history of safe use'"}
        ]
      },
      "escalation_prompt": {
        "trigger": "factual_safety_efficacy_claims_from_preclinical_data",
        "source_doc": "reference/checks_3_4_5.md",
        "source_section": "CHECK_3_PRECLINICAL",
        "steps": [
          {
            "step": 1,
            "name": "claim_classification",
            "executor": "llm",
            "prompt_source": "reference/checks_3_4_5.md#CHECK_3_PRECLINICAL",
            "slots": ["{{S1_TEXT}}", "{{PRECLINICAL_CLAIMS}}", "{{COMPARISON_PAIRS}}"],
            "output_format": {"type": "json", "keys": ["claim_type", "data_source", "caveat_present", "severity"]}
          },
          {
            "step": 2,
            "name": "final_determination",
            "executor": "llm",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative"]
          }
        ]
      }
    },
    {
      "id": "comparative_claims",
      "display_name": "Comparative Claims",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Check whether comparative claims are supported by head-to-head clinical data. Qualifying language ('we believe') does NOT cure the concern.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "comparative_scan",
          "executor": "code",
          "action": "scan for comparative language near candidate name",
          "patterns": ["safer", "more effective", "superior", "differentiated", "best-in-class", "first-in-class", "improved over", "advantage", "compared favorably", "outperform"],
          "short_circuit": "IF none found -> GREEN, skip"
        },
        {
          "step": 2,
          "name": "evidence_search",
          "executor": "code",
          "action": "for each hit, extract 1500 chars context and search for head-to-head evidence",
          "patterns": ["head-to-head", "direct comparison", "comparative trial"],
          "output": "HEAD_TO_HEAD_CITED | NO_DIRECT_COMPARISON per hit"
        },
        {
          "step": 3,
          "name": "llm_comparison",
          "executor": "llm",
          "trigger": "step 2 has any NO_DIRECT_COMPARISON",
          "prompt_template": "The S-1 makes this comparative statement about {{CANDIDATE}}:\n'{{S1_QUOTE}}'\n\nNo head-to-head clinical trial is cited. The SEC has challenged similar language:\n'{{PRECEDENT_COMMENT}}'\n\nIn that case, the SEC asked: '{{SEC_REQUIREMENT}}'\n\nHow does this S-1's language compare?\n(a) Materially similar (same type of unsupported comparison)\n(b) Distinguishable (this S-1 has qualifications the other lacked)\n(c) More aggressive than the language the SEC challenged",
          "slot_sources": {
            "CANDIDATE": "candidate name",
            "S1_QUOTE": "step 1 matched text with context",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_comparative_003.sec_comment_verbatim",
            "SEC_REQUIREMENT": "comment_letter_excerpts.json -> excerpt_comparative_003.what_sec_required"
          }
        }
      ],
      "thresholds": {
        "green": "no comparative claims, or all supported by head-to-head data",
        "yellow": "comparative claims with some qualifications",
        "red": "unqualified comparative claims without head-to-head data"
      },
      "legal_basis_ids": ["rule_408", "section_11"],
      "comment_letter_excerpt_ids": ["excerpt_comparative_001", "excerpt_comparative_002", "excerpt_comparative_003"],
      "comparison_pairs": [
        {
          "id": "nuvalent_comparative",
          "company": "Nuvalent, Inc.",
          "filing_type": "S-1",
          "filing_date": "2021-07-14",
          "s1_text_challenged": "potential best-in-class product candidate[s] — pages 3, 118, 130 and elsewhere",
          "sec_comment_verbatim": "We note your statement on pages 3, 118, 130 and elsewhere in the prospectus that your lead product candidates are 'potential best-in-class product candidate[s].' The term 'best-in-class' suggests that the product candidates are effective and likely to be approved. Please delete these references.",
          "what_sec_required": "Delete all 'best-in-class' references — term implies effectiveness and likely approval",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Clear example of 'best-in-class' being rejected. Even 'potential best-in-class' was rejected."
        },
        {
          "id": "zenas_comparative",
          "company": "Zenas BioPharma, Inc.",
          "filing_type": "S-1",
          "filing_date": "2024-05-15",
          "s1_text_challenged": "Claims that obexelimab is 'safer' and 'more effective' than competitor therapies",
          "sec_comment_verbatim": "We note statements here, and throughout the prospectus, claiming that obexelimab is 'safer' and 'more effective' than anti-CD20 or other anti-CD19 targeting therapies. Qualifying language that statements of safety and efficacy are expressions of the company's beliefs or expectations do not address this concern.",
          "what_sec_required": "Remove 'safer' and 'more effective' claims. Qualifying language ('we believe', 'we expect') does NOT cure the concern.",
          "severity_level": "HIGH",
          "key_rule": "Qualifying language DOES NOT address the concern — this exact sentence overrides the instinct to treat 'we believe' as a hedge",
          "useful_for_comparison_because": "Critical example showing that 'we believe' qualifiers do NOT cure safety/efficacy claims."
        },
        {
          "id": "khosla_valo_comparative",
          "company": "Khosla Ventures / Valo Health",
          "filing_type": "S-4",
          "filing_date": "2021-07-28",
          "s1_text_challenged": "[PLACEHOLDER — to be filled from SEC filing]",
          "sec_comment_verbatim": "Please remove the comparison to S1P1R functional antagonists unless these antagonists were included in a head-to-head clinical trial. Please also remove your disclosure regarding an appropriate safety profile.",
          "what_sec_required": "Remove comparisons unless head-to-head trial conducted. Remove 'appropriate safety profile'. Clarify statistical significance.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Comprehensive example hitting safety comparison, statistical significance, and post-hoc analysis clarity.",
          "_todo": "Fetch S-4 text from SEC EDGAR for CIK 0001841873"
        },
        {
          "id": "curanex_comparative_crossref",
          "company": "Curanex Pharmaceuticals",
          "filing_type": "S-1/A",
          "filing_date": "2024-07-17",
          "s1_text_challenged": "Claims of 'superior anti-inflammatory properties' vs FDA-approved Rezdiffra",
          "sec_comment_verbatim": "You state that Phyto-N boasts superior anti-inflammatory properties and unlike recently FDA approved Rezdiffra, Phyto-N mitigates inflammation occurrence without causing adverse reaction. Please discuss your basis for such claims.",
          "what_sec_required": "Provide basis for superiority claims against approved drugs when only preclinical data exists",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Shows comparing a preclinical candidate favorably to an FDA-approved drug requires direct comparative data."
        }
      ],
      "severity_spectrum": {
        "description": "Comparative claims severity from factual distinction to explicit superiority",
        "levels": [
          {"label": "GREEN_FACTUAL_DISTINCTION", "description": "Factual description of how technology differs from competitors with cautionary language", "example": "'Our approach uses X mechanism, which differs from Y. This is not an indication of effectiveness.'"},
          {"label": "YELLOW_DIFFERENTIATED", "description": "'Differentiated' or 'novel' without implying approval likelihood", "example": "'Our differentiated approach targets X' — borderline, may imply advantage"},
          {"label": "ORANGE_BEST_IN_CLASS", "description": "'Best-in-class' or 'first-in-class' — implies effectiveness and approval", "example": "'Our potential best-in-class candidate' — SEC has consistently rejected this"},
          {"label": "RED_SAFER_MORE_EFFECTIVE", "description": "Direct safety/efficacy comparisons ('safer', 'more effective', 'superior')", "example": "'Safer and more effective than existing therapies'"},
          {"label": "RED_NAMED_COMPETITOR", "description": "Superiority claims against named FDA-approved drugs without head-to-head data", "example": "'Unlike Rezdiffra, our drug does not cause adverse reactions'"}
        ]
      },
      "escalation_prompt": {
        "trigger": "comparative_claim_without_head_to_head_data",
        "source_doc": "reference/checks_3_4_5.md",
        "source_section": "CHECK_4_COMPARATIVE",
        "steps": [
          {
            "step": 1,
            "name": "claim_classification",
            "executor": "llm",
            "prompt_source": "reference/checks_3_4_5.md#CHECK_4_COMPARATIVE",
            "slots": ["{{S1_TEXT}}", "{{COMPARATOR_DRUG}}", "{{COMPARISON_PAIRS}}"],
            "output_format": {"type": "json", "keys": ["claim_type", "comparator_identified", "head_to_head_cited", "qualifier_present", "severity"]}
          },
          {
            "step": 2,
            "name": "qualifier_analysis",
            "executor": "llm",
            "note": "Per Zenas: qualifying language ('we believe') does NOT cure the concern",
            "output_keys": ["qualifier_cures: YES|NO", "rationale"]
          },
          {
            "step": 3,
            "name": "final_determination",
            "executor": "llm",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative"]
          }
        ]
      }
    },
    {
      "id": "fda_communications",
      "display_name": "FDA Communications",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Check whether the S-1 presents a balanced picture of FDA interactions. If positive interactions described, negative feedback should also be disclosed.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "fda_passage_extraction",
          "executor": "code",
          "action": "extract all FDA-related passages",
          "patterns": ["FDA", "Food and Drug Administration", "IND", "NDA", "BLA", "Breakthrough", "Fast Track", "Orphan", "Priority Review", "Accelerated Approval", "pre-IND", "End-of-Phase", "SPA", "CRL", "PDUFA"]
        },
        {
          "step": 2,
          "name": "sentiment_classification",
          "executor": "code",
          "action": "classify each passage as POSITIVE, NEGATIVE, or NEUTRAL",
          "positive_markers": ["aligned", "agreed", "positive feedback", "constructive", "granted", "designated", "approved"],
          "negative_markers": ["denied", "refused", "required additional", "concerns", "deficiency", "refuse to file", "CRL"],
          "output": "classification per passage with section location"
        },
        {
          "step": 3,
          "name": "asymmetry_check",
          "executor": "code",
          "action": "count positive vs negative by section placement",
          "logic": {
            "green": "positive in Business AND negative in Business",
            "yellow": "positive in Business AND negative ONLY in Risk Factors",
            "red": "positive > 0 AND negative == 0 (one-sided)"
          }
        },
        {
          "step": 4,
          "name": "llm_precedent_comparison",
          "executor": "llm",
          "trigger": "step 3 output is YELLOW or RED",
          "prompt_template": "The S-1 describes FDA interactions for {{CANDIDATE}}.\n\nPOSITIVE characterizations (found in {{POS_SECTIONS}}):\n{{POSITIVE_LIST}}\n\nNEGATIVE disclosures (found in {{NEG_SECTIONS}}):\n{{NEGATIVE_LIST}}\n\nIn SEC v. AVEO Pharmaceuticals (LR-24062), the company was charged with fraud for selectively disclosing positive FDA interactions while omitting that the FDA had recommended an additional clinical trial.\n\nIn Tongue v. Sanofi, 816 F.3d 199 (2d Cir. 2016), the court held: '{{TONGUE_HOLDING}}'\n\nCompare this S-1's pattern of FDA disclosure:\n(a) Is there material negative FDA feedback omitted or asymmetrically placed?\n(b) Does the positive characterization create an impression the negative disclosure undermines?\n(c) How does the severity compare to AVEO?",
          "slot_sources": {
            "CANDIDATE": "candidate name",
            "POS_SECTIONS": "step 3 section names",
            "POSITIVE_LIST": "step 2 positive passages",
            "NEG_SECTIONS": "step 3 section names",
            "NEGATIVE_LIST": "step 2 negative passages",
            "TONGUE_HOLDING": "legal_framework.json -> tongue_v_sanofi.key_quotes.no_obligation_to_disclose_everything"
          }
        }
      ],
      "thresholds": {
        "green": "balanced disclosure or no FDA mentions",
        "yellow": "positive in Business, negative only in Risk Factors",
        "red": "positive FDA mentions with zero negative disclosures"
      },
      "legal_basis_ids": ["rule_408", "omnicare"],
      "enforcement_precedent_ids": ["aveo_pharma"],
      "case_law_ids": ["tongue_v_sanofi"],
      "comment_letter_excerpt_ids": ["excerpt_fda_001", "excerpt_fda_002", "excerpt_fda_003"],
      "comparison_pairs": [
        {
          "id": "aerovate_fda",
          "company": "Aerovate Therapeutics, Inc.",
          "filing_type": "S-1",
          "filing_date": "2021-06-02",
          "s1_text_challenged": "[PLACEHOLDER — to be filled from SEC filing]",
          "sec_comment_verbatim": "We note your statement that you have received regulatory guidance from the FDA that your clinical program could support a NDA submission. Please revise to provide context for such statement and balance your disclosure.",
          "what_sec_required": "Balance FDA guidance disclosure with uncertainty language. Remove implications that approval is more likely.",
          "severity_level": "MEDIUM",
          "useful_for_comparison_because": "Shows that positive FDA interactions must be balanced with uncertainty language.",
          "_todo": "Fetch S-1 text from SEC EDGAR for Aerovate CIK 0001798749"
        },
        {
          "id": "annovis_fda",
          "company": "Annovis Bio, Inc.",
          "filing_type": "S-1",
          "filing_date": "2019-06-21",
          "s1_text_challenged": "Expecting efficacy, claiming safety, projecting FDA approval date (2024)",
          "sec_comment_verbatim": "We note your disclosure that you expect your lead compound to be efficacious and that you showed in studies that ANVS-401 was safe on page 1, that you expect to obtain FDA approval in 2024 on page 2.",
          "what_sec_required": "Remove all safety/efficacy claims. Remove projected FDA approval timeline.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Extreme example showing multiple prohibited patterns: efficacy claims, safety claims, and approval timeline projections."
        }
      ],
      "enforcement_actions": [
        {
          "id": "aveo_pharma_enforcement",
          "name": "SEC v. AVEO Pharmaceuticals",
          "citation": "SEC Litigation Release No. 24062 (2018)",
          "relevance": "Fraud charges for selective positive disclosure while omitting negative FDA feedback",
          "source_doc": "reference/checks_3_4_5.md",
          "source_section": "AVEO_ENFORCEMENT"
        }
      ],
      "case_law": [
        {
          "id": "tongue_v_sanofi_ref",
          "name": "Tongue v. Sanofi",
          "citation": "816 F.3d 199 (2d Cir. 2016)",
          "relevance": "Not every fact cutting against an opinion must be disclosed, but Tongue limiting principles often do NOT apply to biotech IPOs",
          "source_doc": "reference/checks_3_4_5.md",
          "source_section": "TONGUE_V_SANOFI"
        }
      ],
      "two_test_framework": {
        "balance_test": "If positive FDA interactions described, are negative interactions also disclosed?",
        "framing_test": "Do positive characterizations imply approval is likely or accelerated?",
        "section_placement": "Are positives in Business/Summary while negatives are only in Risk Factors?"
      },
      "severity_spectrum": {
        "description": "FDA communication severity depends on balance, framing, and section placement",
        "levels": [
          {"label": "GREEN_CLEAR", "description": "Balanced disclosure — positive and negative FDA interactions both described, no approval timeline projection", "example": "S-1 describes Breakthrough Therapy designation while noting FDA required additional trials"},
          {"label": "YELLOW_ASYMMETRIC", "description": "Positive in Business/Summary, negative only in Risk Factors; or positive framing implies accelerated path without caveats", "example": "Business section describes 'positive FDA feedback' while Risk Factors mention 'FDA required additional studies'"},
          {"label": "RED_ONE_SIDED", "description": "Positive FDA mentions with zero negative disclosures, or projected approval timelines; matches AVEO pattern", "example": "'We expect to obtain FDA approval in 2024' or selective disclosure of positive interactions only"}
        ]
      },
      "escalation_prompt": {
        "trigger": "asymmetric_fda_disclosure_or_approval_implications",
        "source_doc": "reference/checks_3_4_5.md",
        "source_section": "CHECK_5_FDA",
        "steps": [
          {
            "step": 1,
            "name": "balance_and_framing_test",
            "executor": "llm",
            "prompt_source": "reference/checks_3_4_5.md#CHECK_5_FDA",
            "slots": ["{{POSITIVE_FDA_PASSAGES}}", "{{NEGATIVE_FDA_PASSAGES}}", "{{SECTION_PLACEMENT}}"],
            "output_format": {"type": "json", "keys": ["balance_result", "framing_result", "aveo_similarity", "severity"]}
          },
          {
            "step": 2,
            "name": "final_determination",
            "executor": "llm",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative"]
          }
        ]
      }
    },
    {
      "id": "pipeline_accuracy",
      "display_name": "Pipeline Accuracy",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Check whether the S-1 pipeline table/graphic matches text descriptions and ClinicalTrials.gov data.",
      "requires_ctgov": false,
      "steps": [
        {
          "step": 1,
          "name": "format_detection",
          "executor": "code",
          "action": "detect pipeline format: HTML table or embedded image",
          "output": "HTML_TABLE | IMAGE"
        },
        {
          "step": 2,
          "name": "image_fallback",
          "executor": "code",
          "trigger": "step 1 output is IMAGE",
          "output": "YELLOW — 'Pipeline is embedded as an image and cannot be verified programmatically. Manual review recommended.'"
        },
        {
          "step": 3,
          "name": "table_comparison",
          "executor": "code",
          "trigger": "step 1 output is HTML_TABLE",
          "action": "extract phase claims per candidate from table, compare to text passages",
          "output": "MATCH | MISMATCH per candidate"
        },
        {
          "step": 4,
          "name": "overstated_progress_check",
          "executor": "code",
          "trigger": "step 1 output is HTML_TABLE",
          "logic": {
            "red": "table shows Phase 2 but text only describes Phase 1 data",
            "yellow": "table shows IND-enabling but no IND filed"
          }
        }
      ],
      "thresholds": {
        "green": "HTML table matches text descriptions",
        "yellow": "image (cannot verify) or minor inconsistency",
        "red": "table overstates development progress vs text"
      },
      "legal_basis_ids": ["rule_408", "section_11"],
      "comment_letter_excerpt_ids": ["excerpt_phase_003"],
      "comparison_pairs": [
        {
          "id": "taysha_pipeline",
          "company": "Taysha Gene Therapies, Inc.",
          "filing_type": "S-1",
          "filing_date": "2020-09-24",
          "s1_text_challenged": "Pipeline table showing combined Phase 1/2 for all products, 'Pivotal' instead of Phase 3",
          "sec_comment_verbatim": "Include separate columns for Phase 1 and Phase 2 trials or tell us the basis for your belief. Also replace 'Pivotal' with 'Phase 3' and merge 'preclinical' and 'IND-enabling' columns.",
          "what_sec_required": "Separate phases in pipeline table, use standard phase terminology, merge preclinical columns",
          "severity_level": "MEDIUM",
          "useful_for_comparison_because": "Shows SEC requirements for pipeline table formatting including standard phase terminology."
        }
      ],
      "severity_spectrum": {
        "description": "Pipeline accuracy depends on format and consistency with text",
        "levels": [
          {"label": "GREEN_CLEAR", "description": "HTML table matches text descriptions and uses standard phase terminology", "example": "Table shows Phase 1 for Drug A, text consistently describes Phase 1 trial"},
          {"label": "YELLOW_IMAGE", "description": "Pipeline is embedded as image — cannot verify programmatically", "example": "Pipeline graphic as PNG/JPG, requires manual review"},
          {"label": "RED_MISMATCH", "description": "Table overstates progress vs text or uses non-standard terminology", "example": "Table shows Phase 2 but text only describes Phase 1 data; 'Pivotal' used instead of Phase 3"}
        ]
      },
      "escalation_prompt": {
        "trigger": "pipeline_table_mismatch_or_non_standard_terminology",
        "source_doc": "reference/checks_6_7.md",
        "source_section": "CHECK_6_PIPELINE",
        "steps": [
          {
            "step": 1,
            "name": "table_analysis",
            "executor": "llm",
            "prompt_source": "reference/checks_6_7.md#CHECK_6_PIPELINE",
            "slots": ["{{PIPELINE_TABLE}}", "{{TEXT_DESCRIPTIONS}}", "{{CTGOV_DATA}}"],
            "output_format": {"type": "json", "keys": ["format_type", "consistency_issues", "terminology_issues", "severity"]}
          },
          {
            "step": 2,
            "name": "final_determination",
            "executor": "llm",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative"]
          }
        ]
      }
    },
    {
      "id": "red_flag_phrases",
      "display_name": "Red Flag Phrases",
      "layer": 1,
      "pass": "pass_1_crosscutting",
      "description": "Scan for SEC-challenged safety/efficacy language. Classify each hit as cautionary (GREEN), data-supported (GREEN), or standalone (FLAG).",
      "requires_ctgov": false,
      "phrase_source": "reference/red_flag_phrases.txt",
      "steps": [
        {
          "step": 1,
          "name": "phrase_scan",
          "executor": "code",
          "action": "for each phrase in red_flag_phrases.txt, scan all candidate passages",
          "output": "list of {phrase, sentence, section, page_approx, context_500chars}"
        },
        {
          "step": 2,
          "name": "context_classification",
          "executor": "code",
          "action": "classify each hit into categories",
          "categories": {
            "A_CAUTIONARY": {
              "criteria": "phrase in Risk Factor section OR conditional context (may not be, cannot assure, no guarantee of)",
              "result": "AUTO GREEN"
            },
            "B_SUPPORTED": {
              "criteria": "quantitative data within 500 chars (n/N, %, AE rates, p-values, dose/response)",
              "result": "AUTO GREEN"
            },
            "C_STANDALONE": {
              "criteria": "affirmative use, no nearby data, not cautionary",
              "result": "FLAG for step 3"
            }
          }
        },
        {
          "step": 3,
          "name": "llm_standalone_assessment",
          "executor": "llm",
          "trigger": "step 2 has CATEGORY C hits",
          "prompt_template": "The S-1 uses '{{PHRASE}}' in this context:\n'{{S1_PASSAGE}}'\nSection: {{SECTION}}, approx. page {{PAGE}}\n\nThis usage is:\n- Not in a cautionary/conditional context\n- Not immediately supported by quantitative data\n\nThe SEC has challenged similar language. In a comment letter to {{COMPANY}}, the SEC stated:\n'{{SEC_COMMENT}}'\nThe S-1 language that triggered this comment was:\n'{{TRIGGERED_LANGUAGE}}'\n\nCompare this S-1's usage:\n(a) Comparable — similar standalone use without data support\n(b) Distinguishable — this context provides implicit support\n(c) Worse — more affirmative/absolute than the challenged language",
          "slot_sources": {
            "PHRASE": "step 1 matched phrase",
            "S1_PASSAGE": "step 1 context",
            "SECTION": "step 1 section name",
            "PAGE": "step 1 page_approx",
            "COMPANY": "comment_letter_excerpts.json -> matching topic excerpt.company",
            "SEC_COMMENT": "comment_letter_excerpts.json -> matching topic excerpt.sec_comment_verbatim",
            "TRIGGERED_LANGUAGE": "comment_letter_excerpts.json -> matching topic excerpt.s1_language_challenged"
          }
        },
        {
          "step": 4,
          "name": "accumulation_check",
          "executor": "code",
          "action": "count total STANDALONE instances per phrase",
          "threshold": "IF any phrase has >10 STANDALONE instances -> PATTERN flag"
        }
      ],
      "thresholds": {
        "green": "no standalone instances, or all cautionary/supported",
        "yellow": "standalone instances found but not matching precedent pattern",
        "red": ">10 standalone instances of same phrase, or closely matching precedent"
      },
      "legal_basis_ids": ["rule_408"],
      "comment_letter_excerpt_ids": ["excerpt_safety_001", "excerpt_safety_002", "excerpt_safety_003", "excerpt_safety_004", "excerpt_safety_005"],
      "comparison_pairs": [
        {
          "id": "altamira_red_flags",
          "company": "Altamira Therapeutics Ltd.",
          "filing_type": "F-1",
          "filing_date": "2023-02-24",
          "s1_text_challenged": "'safe and effective', 'safe and well tolerated', 'favorable safety profile' — used on multiple pages",
          "sec_comment_verbatim": "We note statements in numerous places throughout the registration statement stating or suggesting that your OligoPhore and SemaPhore peptide polyplex platform technology is 'safe and effective.' Please remove all statements throughout your registration statement that state or imply your conclusions regarding the safety or efficacy of your product candidates.",
          "what_sec_required": "Remove ALL statements stating or implying safety/efficacy conclusions. 'Well-tolerated' (if true) and 'no SAEs reported' are acceptable.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Comprehensive anchor example showing the full range of prohibited safety/efficacy language."
        },
        {
          "id": "graybug_red_flags",
          "company": "Graybug Vision, Inc.",
          "filing_type": "S-1",
          "filing_date": "2020-08-27",
          "s1_text_challenged": "'favorable safety and tolerability' — page 21 and elsewhere",
          "sec_comment_verbatim": "Please revise your disclosure to remove your characterization of GB-102 as safe, as a determination of whether a product candidate is safe is solely within the authority of the FDA.",
          "what_sec_required": "Remove characterization as 'safe'. 'Well tolerated' and SAE count disclosures are acceptable.",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Shows that 'favorable safety and tolerability' is treated the same as 'safe'."
        },
        {
          "id": "madrigal_red_flags",
          "company": "Madrigal Pharmaceuticals, Inc.",
          "filing_type": "10-K",
          "filing_date": "2023-11-21",
          "s1_text_challenged": "'Resmetirom was safe and well tolerated' — page 10",
          "sec_comment_verbatim": "Determinations related to safety are within the sole authority of the FDA. Additionally, please disclose all serious adverse events related to Resmetirom. Explain how you have determined that the candidate is well tolerated when trial participants experienced serious adverse events.",
          "what_sec_required": "Three-part: (a) stop safety assessments, (b) disclose all SAEs, (c) explain basis for 'well tolerated' given SAEs occurred",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Shows SEC challenges even 'well tolerated' when SAEs have occurred. Three-part structure is a common pattern.",
          "three_part_test": true
        },
        {
          "id": "scopus_red_flags",
          "company": "Scopus BioPharma Inc.",
          "filing_type": "Form 1-A",
          "filing_date": "2020-06-24",
          "s1_text_challenged": "'acceptable safety profile'",
          "sec_comment_verbatim": "Safety is a determination that is solely within the authority of the FDA or similar foreign regulators. You may state that your product candidates are well tolerated if true. Please revise this statement accordingly.",
          "what_sec_required": "Remove 'acceptable safety profile'; 'well tolerated if true' is acceptable",
          "severity_level": "HIGH",
          "useful_for_comparison_because": "Shows 'acceptable safety profile' is treated as a prohibited safety determination."
        },
        {
          "id": "os_therapies_red_flags",
          "company": "OS Therapies Inc",
          "filing_type": "S-1",
          "filing_date": "2023-03-27",
          "s1_text_challenged": "'the data presented from the Phase Ib trial demonstrated that ADXS31-164 was well tolerated' — SEC required substantiation, not removal",
          "sec_comment_verbatim": "Please further revise to present the Phase 1b endpoints, the trial results, and your conclusions with respect to the primary and secondary endpoints. Investors should be able to assess how the drug candidate performed relative to the established endpoints.",
          "what_sec_required": "Present endpoints, results, and conclusions. Disclose statistical significance. Provide enough data for investors to verify 'well tolerated' claim.",
          "severity_level": "MEDIUM",
          "useful_for_comparison_because": "Shows SEC nuanced approach: 'well tolerated' NOT rejected but required substantiating endpoint data."
        }
      ],
      "three_tier_classification": {
        "source_doc": "reference/checks_6_7.md",
        "source_section": "THREE_TIER_CLASSIFICATION",
        "tier_1_always_challenged": ["safe", "effective", "safe and effective", "safe and well tolerated", "proven safety", "proven efficacy", "established safety", "established efficacy", "favorable safety profile", "acceptable safety profile", "demonstrated efficacy", "demonstrated safety", "superior", "best-in-class"],
        "tier_2_challenged_unless_supported": ["well-tolerated", "well tolerated", "favorable tolerability", "favorable safety and tolerability"],
        "tier_3_context_dependent": ["no serious adverse events", "no SAEs", "no treatment-related SAEs", "preliminary", "preliminary data"]
      },
      "severity_spectrum": {
        "description": "Red flag phrase severity depends on tier, context, and accumulation",
        "levels": [
          {"label": "GREEN_CLEAR", "description": "Phrase in cautionary context (Risk Factors) or with supporting data", "example": "'Well-tolerated' immediately followed by AE rates and SAE counts"},
          {"label": "YELLOW_BORDERLINE", "description": "Tier 2 phrase without nearby supporting data, or Tier 3 phrase without context", "example": "'Well-tolerated' in Business section without nearby AE data"},
          {"label": "RED_MATCHES_CHALLENGED", "description": "Tier 1 phrase in any standalone context, or >10 standalone instances of any phrase", "example": "'Safe and effective' in Prospectus Summary"}
        ]
      },
      "escalation_prompt": {
        "trigger": "standalone_tier_1_or_tier_2_phrases_or_accumulation_pattern",
        "source_doc": "reference/checks_6_7.md",
        "source_section": "ESCALATION_PROMPT_CHECK7",
        "steps": [
          {
            "step": 1,
            "name": "instance_by_instance_analysis",
            "executor": "llm",
            "prompt_source": "reference/checks_6_7.md#ESCALATION_PROMPT_CHECK7",
            "slots": ["{{PHRASE}}", "{{S1_TEXT}}", "{{SECTION}}", "{{PAGE}}", "{{COMPARISON_PAIRS}}"],
            "sub_questions": ["What tier is this phrase?", "Is it cautionary or standalone?", "Is data within 500 chars?", "What section is it in?", "Does it match a challenged pattern?", "What is the severity?"],
            "output_format": {"type": "json", "keys": ["tier", "context_type", "nearby_data", "section", "matches_precedent", "severity"]}
          },
          {
            "step": 2,
            "name": "global_madrigal_three_part_test",
            "executor": "llm",
            "description": "Apply Madrigal three-part test across entire S-1: (a) safety assessments, (b) SAE disclosure, (c) basis for tolerability claims given SAEs",
            "output_keys": ["part_a_result", "part_b_result", "part_c_result", "overall_assessment"]
          },
          {
            "step": 3,
            "name": "web_search",
            "executor": "web_search",
            "trigger": "fires_on_RED_or_multiple_YELLOW",
            "query_template": "SEC comment letter safety characterization well-tolerated biotech {{YEAR_RANGE}}",
            "output_keys": ["search_result", "assessment: STRENGTHEN|WEAKEN|NEUTRAL"]
          },
          {
            "step": 4,
            "name": "final_determination",
            "executor": "llm",
            "output_keys": ["final_status: GREEN|YELLOW|RED", "narrative", "tier_1_count", "tier_2_unsupported_count"]
          }
        ]
      }
    },
    {
      "id": "trial_design_comparison",
      "display_name": "Trial Design Match",
      "layer": 1,
      "pass": "pass_2_trial_level",
      "description": "Compare S-1 trial design descriptions against ClinicalTrials.gov registered design elements.",
      "requires_ctgov": true,
      "steps": [
        {
          "step": 1,
          "name": "ctgov_extraction",
          "executor": "code",
          "action": "extract design elements from CTgov JSON",
          "fields": [
            "protocolSection.designModule.phases",
            "protocolSection.designModule.designInfo.allocation",
            "protocolSection.designModule.designInfo.maskingInfo.masking",
            "protocolSection.designModule.enrollmentInfo.count",
            "protocolSection.designModule.enrollmentInfo.type",
            "protocolSection.armsInterventionsModule.armGroups",
            "protocolSection.outcomesModule.primaryOutcomes",
            "protocolSection.outcomesModule.secondaryOutcomes"
          ]
        },
        {
          "step": 2,
          "name": "s1_element_search",
          "executor": "code",
          "action": "for each element, search S-1 passages for match",
          "element_patterns": {
            "phase": ["Phase [n]"],
            "allocation": ["randomized", "non-randomized", "single-arm"],
            "masking": ["double-blind", "open-label", "single-blind", "placebo-controlled"],
            "enrollment": ["[number] near patients|subjects|participants|enrolled"],
            "endpoints": ["each endpoint measure term"]
          }
        },
        {
          "step": 3,
          "name": "element_marking",
          "executor": "code",
          "action": "mark each element",
          "statuses": ["MATCH", "ABSENT", "PARTIAL", "MISMATCH"],
          "color_coding": {
            "green": "MATCH",
            "yellow": "PARTIAL or ABSENT (non-critical element)",
            "red": "MISMATCH or ABSENT (critical element like primary endpoint)"
          }
        },
        {
          "step": 4,
          "name": "llm_materiality",
          "executor": "llm",
          "trigger": "step 3 has ABSENT or MISMATCH items",
          "prompt_template": "This trial element is {{STATUS}}:\nCTgov says: {{CTGOV_VALUE}}\nS-1 says: {{S1_PASSAGE}}\n\nThe SEC has required disclosure of this element:\n'{{PRECEDENT_COMMENT}}'\n\nWould a reasonable investor consider this omission/mismatch important?",
          "slot_sources": {
            "STATUS": "step 3 status",
            "CTGOV_VALUE": "step 1 extracted value",
            "S1_PASSAGE": "step 2 found text or 'not found'",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_trial_design_001 or _002"
          }
        }
      ],
      "legal_basis_ids": ["rule_408"],
      "comment_letter_excerpt_ids": ["excerpt_trial_design_001", "excerpt_trial_design_002", "excerpt_trial_design_003"]
    },
    {
      "id": "endpoints_statistics",
      "display_name": "Endpoint Hierarchy",
      "layer": 1,
      "pass": "pass_2_trial_level",
      "description": "The Harkonen Check. Verify endpoint hierarchy is clear, primary results prominently disclosed, no leading with secondary/post-hoc while burying primary failure.",
      "requires_ctgov": true,
      "steps": [
        {
          "step": 1,
          "name": "endpoint_extraction",
          "executor": "code",
          "action": "extract endpoint hierarchy from CTgov",
          "fields": ["primaryOutcomes", "secondaryOutcomes", "resultsSection.outcomeMeasures (if exists)"],
          "output": "endpoint list with type and results (if posted)"
        },
        {
          "step": 2,
          "name": "s1_endpoint_mapping",
          "executor": "code",
          "action": "map S-1 passages to endpoints",
          "output": "DISCUSSED | NOT_DISCUSSED per endpoint"
        },
        {
          "step": 3,
          "name": "headline_identification",
          "executor": "code",
          "action": "identify S-1 headline finding (first efficacy result in Prospectus Summary or Business section)",
          "output": "headline finding text and section"
        },
        {
          "step": 4,
          "name": "harkonen_pattern_check",
          "executor": "code",
          "action": "check three conditions",
          "conditions": {
            "A": "headline finding is from SECONDARY or unregistered endpoint",
            "B": "PRIMARY endpoint not discussed OR showed null/negative result not highlighted",
            "C": "S-1 does not label headline finding as secondary/exploratory"
          },
          "logic": {
            "red": "A AND B AND C (Harkonen pattern)",
            "yellow": "A AND B but S-1 labels it as secondary",
            "green": "primary endpoint prominently discussed"
          }
        },
        {
          "step": 5,
          "name": "llm_precedent_comparison",
          "executor": "llm",
          "trigger": "step 4 is YELLOW or RED",
          "prompt_template": "ENDPOINT HIERARCHY ANALYSIS\n\nClinicalTrials.gov shows:\nPRIMARY endpoint: {{PRIMARY_MEASURE}} -- Result: {{PRIMARY_RESULT}}\nSECONDARY endpoints: {{SECONDARY_LIST}} -- Results: {{SECONDARY_RESULTS}}\n\nThe S-1 presents this trial as follows:\nHEADLINE (first mention): '{{S1_HEADLINE}}' ({{SECTION}}, p. {{PAGE}})\nPrimary endpoint discussion: '{{S1_PRIMARY_QUOTE}}'\n\nPRECEDENT COMPARISON:\n\nIn United States v. Harkonen (InterMune):\n- Primary endpoint: PFS -> FAILED\n- Press release headline: '{{HARKONEN_HEADLINE}}'\n- Post-hoc subgroup presented as primary finding\n- Criminal wire fraud conviction\n\nIn SEC v. Clovis Oncology:\n- Reported 60% ORR using unconfirmed responses\n- Confirmed ORR was 28%\n- $20M penalty\n\nCompare:\n1. Is the headline from the primary endpoint?\n2. If not, is the primary also disclosed?\n3. Is the hierarchy clearly stated?\n4. Rate similarity to Harkonen: HIGH / MODERATE / LOW / NOT APPLICABLE",
          "slot_sources": {
            "PRIMARY_MEASURE": "step 1 primary endpoints",
            "PRIMARY_RESULT": "step 1 results if posted",
            "SECONDARY_LIST": "step 1 secondary endpoints",
            "SECONDARY_RESULTS": "step 1 results if posted",
            "S1_HEADLINE": "step 3 headline text",
            "SECTION": "step 3 section",
            "PAGE": "step 3 page",
            "S1_PRIMARY_QUOTE": "step 2 primary endpoint S-1 text or 'NOT FOUND'",
            "HARKONEN_HEADLINE": "legal_framework.json -> harkonen_intermune.facts.fraudulent_press_release_headline"
          }
        }
      ],
      "legal_basis_ids": ["rule_408", "matrixx", "tsc_industries"],
      "enforcement_precedent_ids": ["harkonen_intermune", "clovis"],
      "comment_letter_excerpt_ids": ["excerpt_stats_001", "excerpt_stats_002", "excerpt_stats_003", "excerpt_trial_design_003"]
    },
    {
      "id": "safety_comparison",
      "display_name": "Safety Data Match",
      "layer": 1,
      "pass": "pass_2_trial_level",
      "description": "Compare S-1 safety characterizations against CTgov adverse event data. Check FDAAA 801 results posting compliance.",
      "requires_ctgov": true,
      "steps": [
        {
          "step": 1,
          "name": "ctgov_safety_extraction",
          "executor": "code",
          "action": "extract AE data from CTgov results",
          "fields": ["adverseEventsModule.eventGroups", "adverseEventsModule.seriousEvents", "adverseEventsModule.otherEvents"],
          "calculations": ["overall AE rate", "SAE rate", "death rate per arm"]
        },
        {
          "step": 2,
          "name": "s1_safety_extraction",
          "executor": "code",
          "action": "extract safety characterizations from S-1",
          "patterns": ["well-tolerated", "safe", "safety profile", "adverse", "SAE", "serious adverse", "TEAE", "treatment-emergent", "death"]
        },
        {
          "step": 3,
          "name": "direct_comparison",
          "executor": "code",
          "action": "compare each S-1 claim to CTgov data",
          "output": "SUPPORTED | CONTRADICTED | UNVERIFIABLE per claim"
        },
        {
          "step": 4,
          "name": "fdaaa_801_check",
          "executor": "code",
          "action": "check results posting compliance",
          "logic": {
            "red": "status == COMPLETED AND no resultsSection AND months_since_completion > 12",
            "yellow": "status == COMPLETED AND no resultsSection AND months_since_completion <= 12",
            "info": "results posted or trial not yet completed"
          }
        },
        {
          "step": 5,
          "name": "llm_discrepancy_assessment",
          "executor": "llm",
          "trigger": "step 3 has any CONTRADICTED",
          "prompt_template": "SAFETY DATA COMPARISON\n\nThe S-1 states: '{{S1_SAFETY_CLAIM}}' ({{SECTION}}, p. {{PAGE}})\n\nClinicalTrials.gov data:\n- Overall AE rate: {{DRUG_AE}} vs {{PLACEBO_AE}}\n- SAE rate: {{DRUG_SAE}} vs {{PLACEBO_SAE}}\n- Deaths: {{DRUG_DEATHS}} vs {{PLACEBO_DEATHS}}\n- Top 5 AEs: {{AE_LIST}}\n\nThe S-1's characterization appears {{STATUS}} because {{REASON}}.\n\nThe SEC has challenged similar characterizations:\n'{{PRECEDENT_COMMENT}}'\n\nCompare the severity of the discrepancy to the language the SEC challenged. How material is the gap?",
          "slot_sources": {
            "S1_SAFETY_CLAIM": "step 2 matched text",
            "SECTION": "passage section",
            "PAGE": "passage page_approx",
            "DRUG_AE": "step 1 calculation",
            "PLACEBO_AE": "step 1 calculation",
            "DRUG_SAE": "step 1 calculation",
            "PLACEBO_SAE": "step 1 calculation",
            "DRUG_DEATHS": "step 1 extraction",
            "PLACEBO_DEATHS": "step 1 extraction",
            "AE_LIST": "step 1 top 5 AEs",
            "STATUS": "step 3 result",
            "REASON": "step 3 reason",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_safety_003.sec_comment_verbatim"
          }
        }
      ],
      "legal_basis_ids": ["matrixx", "omnicare", "rule_408", "fdaaa_801"],
      "comment_letter_excerpt_ids": ["excerpt_safety_001", "excerpt_safety_002", "excerpt_safety_003", "excerpt_safety_005"]
    },
    {
      "id": "data_maturity",
      "display_name": "Data Maturity",
      "layer": 1,
      "pass": "pass_2_trial_level",
      "description": "Check whether preliminary/interim data is labeled as such. Flag conclusory language for immature data.",
      "requires_ctgov": true,
      "steps": [
        {
          "step": 1,
          "name": "trial_status_check",
          "executor": "code",
          "action": "determine trial status from CTgov",
          "fields": ["overallStatus", "resultsSection exists?"],
          "output": "status and results_posted boolean"
        },
        {
          "step": 2,
          "name": "labeling_check",
          "executor": "code",
          "trigger": "status != COMPLETED",
          "action": "search S-1 for data maturity labels",
          "patterns": ["interim", "preliminary", "topline", "initial", "data cutoff"],
          "output": "LABELED_PRELIMINARY | NOT_LABELED",
          "threshold": "IF NOT_LABELED and trial ongoing -> YELLOW"
        },
        {
          "step": 3,
          "name": "conclusory_language_check",
          "executor": "code",
          "trigger": "trial ongoing OR no results OR S-1 says preliminary",
          "action": "search for conclusory verbs in same passages",
          "patterns": ["demonstrated", "established", "proven", "confirmed", "showed", "validated"],
          "output": "count of conclusory terms"
        },
        {
          "step": 4,
          "name": "llm_maturity_assessment",
          "executor": "llm",
          "trigger": "step 3 finds conclusory terms",
          "prompt_template": "The S-1 presents data from {{TRIAL_STATUS}} and uses:\n'{{S1_PASSAGE}}'\n\nThe conclusory term '{{VERB}}' is used for data that is {{DATA_MATURITY}}.\n\nIn In re Rigel Pharmaceuticals, 697 F.3d 869 (9th Cir. 2012), the court held:\n'{{RIGEL_HOLDING}}'\n\nThe SEC has challenged conclusory language for preliminary data:\n'{{PRECEDENT_COMMENT}}'\n\nIs the conclusory framing appropriate given the data maturity?",
          "slot_sources": {
            "TRIAL_STATUS": "step 1 status",
            "S1_PASSAGE": "step 3 passage with conclusory term",
            "VERB": "step 3 matched term",
            "DATA_MATURITY": "step 1 status description",
            "RIGEL_HOLDING": "legal_framework.json -> rigel_pharma.key_quotes.partial_disclosure_standard",
            "PRECEDENT_COMMENT": "comment_letter_excerpts.json -> excerpt_trial_design_003.sec_comment_verbatim"
          }
        }
      ],
      "legal_basis_ids": ["rule_408", "rigel_pharma"],
      "comment_letter_excerpt_ids": ["excerpt_trial_design_003", "excerpt_stats_002"]
    }
  ],
  "escalation_checks": [
    {
      "id": "omnicare_test",
      "display_name": "Omnicare Opinion Test",
      "layer": 2,
      "trigger": "Layer 1 YELLOW or RED involving opinion/characterization",
      "legal_basis_id": "omnicare",
      "prompt_template_id": "omnicare_escalation",
      "output_format": {
        "columns": ["Statement", "Impression Created", "Test 2 (Embedded Fact)", "Test 3 (Contrary Facts)", "Fairly Aligns?", "Risk Level"],
        "risk_levels": ["SIGNIFICANT RISK", "MODERATE RISK", "LOW RISK", "NO CONCERN"]
      }
    },
    {
      "id": "rule_408_pattern",
      "display_name": "Rule 408 Pattern Analysis",
      "layer": 2,
      "trigger": "Multiple YELLOW or RED findings from Layer 1",
      "legal_basis_id": "rule_408",
      "thresholds": {
        "green": "favors_company < 50% or total findings < 3",
        "yellow": "50-75% favors company",
        "red": ">= 75% favors company"
      },
      "output_format": {
        "columns": ["#", "Omission/Gap", "Direction", "Source Check"]
      }
    },
    {
      "id": "matrixx_check",
      "display_name": "Matrixx Significance Check",
      "layer": 2,
      "trigger": "Any finding involving small trial (N<30) or statistical significance argument",
      "legal_basis_id": "matrixx",
      "note": "Defense-blocker, not independent check. Prevents dismissal of findings on statistical significance grounds."
    }
  ]
}
